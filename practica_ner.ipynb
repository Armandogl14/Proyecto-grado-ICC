{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.cli import train\n",
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Asegurarse de que tenemos las dependencias necesarias\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy download es_core_news_md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_bio_to_spacy(bio_data):\n",
        "    \"\"\"\n",
        "    Convierte datos en formato BIO a formato de entrenamiento de spaCy\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    \n",
        "    for sentence in bio_data:\n",
        "        text = ' '.join([word for word, tag in sentence])\n",
        "        entities = []\n",
        "        \n",
        "        current_entity = None\n",
        "        start_char = 0\n",
        "        \n",
        "        for word, tag in sentence:\n",
        "            end_char = start_char + len(word)\n",
        "            \n",
        "            if tag.startswith('B-'):  # Inicio de una nueva entidad\n",
        "                if current_entity:\n",
        "                    entities.append(current_entity)\n",
        "                current_entity = {'start': start_char, 'end': end_char, 'label': tag[2:]}\n",
        "            \n",
        "            elif tag.startswith('I-'):  # Continuación de una entidad\n",
        "                if current_entity and current_entity['label'] == tag[2:]:\n",
        "                    current_entity['end'] = end_char\n",
        "                \n",
        "            else:  # Tag O - No es parte de una entidad\n",
        "                if current_entity:\n",
        "                    entities.append(current_entity)\n",
        "                    current_entity = None\n",
        "            \n",
        "            start_char = end_char + 1  # +1 para el espacio\n",
        "        \n",
        "        if current_entity:  # Añadir la última entidad si existe\n",
        "            entities.append(current_entity)\n",
        "        \n",
        "        training_data.append((text, {'entities': entities}))\n",
        "    \n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir los datos de entrenamiento y prueba al formato de spaCy\n",
        "spacy_train_data = convert_bio_to_spacy(train_data)\n",
        "spacy_test_data = convert_bio_to_spacy(test_data)\n",
        "\n",
        "# Crear un nuevo modelo vacío de spaCy\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Añadir el pipeline de NER\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "# Añadir las etiquetas al reconocedor de entidades\n",
        "for _, annotations in spacy_train_data:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "        ner.add_label(ent[\"label\"])\n",
        "\n",
        "# Configurar el entrenamiento\n",
        "n_iter = 30\n",
        "batch_size = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar el modelo\n",
        "with nlp.disable_pipes(*[pipe for pipe in nlp.pipe_names if pipe != \"ner\"]):\n",
        "    optimizer = nlp.begin_training()\n",
        "    \n",
        "    # Mostrar progreso con tqdm\n",
        "    for itn in tqdm(range(n_iter), desc=\"Training epochs\"):\n",
        "        random.shuffle(spacy_train_data)\n",
        "        losses = {}\n",
        "        \n",
        "        # Batch the examples\n",
        "        batches = minibatch(spacy_train_data, size=batch_size)\n",
        "        for batch in batches:\n",
        "            texts, annotations = zip(*batch)\n",
        "            nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "            \n",
        "        print(f\"Losses at iteration {itn}: {losses}\")\n",
        "\n",
        "# Guardar el modelo\n",
        "nlp.to_disk(\"restaurant_ner_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "def evaluate_ner(nlp, test_data):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for text, annotations in test_data:\n",
        "        doc = nlp(text)\n",
        "        gold_entities = annotations['entities']\n",
        "        pred_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
        "        \n",
        "        # Comparar entidades predichas con las reales\n",
        "        for gold_ent in gold_entities:\n",
        "            total += 1\n",
        "            for pred_start, pred_end, pred_label in pred_entities:\n",
        "                if (gold_ent['start'] == pred_start and \n",
        "                    gold_ent['end'] == pred_end and \n",
        "                    gold_ent['label'] == pred_label):\n",
        "                    correct += 1\n",
        "                    break\n",
        "    \n",
        "    precision = correct / total if total > 0 else 0\n",
        "    return precision\n",
        "\n",
        "# Cargar el modelo entrenado y evaluarlo\n",
        "trained_nlp = spacy.load(\"restaurant_ner_model\")\n",
        "precision = evaluate_ner(trained_nlp, spacy_test_data)\n",
        "print(f\"Precisión del modelo en el conjunto de prueba: {precision:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejemplo de uso del modelo entrenado\n",
        "def test_model_on_text(nlp, text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Probar con algunas oraciones de ejemplo\n",
        "test_sentences = [\n",
        "    \"The Thai restaurant on Main Street has great pad thai\",\n",
        "    \"I had dinner at Le Bernardin last night and the service was excellent\",\n",
        "    \"The prices at Sushi Express are very reasonable\"\n",
        "]\n",
        "\n",
        "print(\"Ejemplos de predicciones del modelo:\")\n",
        "for sentence in test_sentences:\n",
        "    entities = test_model_on_text(trained_nlp, sentence)\n",
        "    print(f\"\\nTexto: {sentence}\")\n",
        "    print(\"Entidades encontradas:\")\n",
        "    for text, label in entities:\n",
        "        print(f\"- {text}: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir los datos de entrenamiento y prueba al formato de spaCy\n",
        "spacy_train_data = convert_bio_to_spacy(train_data)\n",
        "spacy_test_data = convert_bio_to_spacy(test_data)\n",
        "\n",
        "# Crear un nuevo modelo vacío de spaCy\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Añadir el pipeline de NER\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "# Añadir las etiquetas al reconocedor de entidades\n",
        "for _, annotations in spacy_train_data:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "        ner.add_label(ent[\"label\"])\n",
        "\n",
        "# Deshabilitar otros componentes durante el entrenamiento\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
